{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFFWJ56XXFyR",
        "outputId": "e3904c23-97cc-48db-fe8e-be66302f336d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_model_optimization as tfmot\n",
        "import numpy as np\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6hkzSQfYbck"
      },
      "source": [
        "# Loading and Preprocessing Data\n",
        "We are now loading and preprocessing the CIFAR-10 dataset. This step involves resizing the images and normalizing them to prepare for model training. The use of a consistent data format is crucial for effective model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MlFJvz_pX7nV"
      },
      "outputs": [],
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "def load_or_train_model(train_ds, test_ds, model_path, is_pruned=False):\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"Loading saved model...\")\n",
        "        if is_pruned:\n",
        "            # Use the prune_scope for loading pruned models\n",
        "            with tfmot.sparsity.keras.prune_scope():\n",
        "                return tf.keras.models.load_model(model_path)\n",
        "        else:\n",
        "            return tf.keras.models.load_model(model_path)\n",
        "    else:\n",
        "        print(\"Training new model...\")\n",
        "        model = create_and_train_model(train_ds, test_ds)\n",
        "        model.save(model_path)\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyG7emS5bgo9"
      },
      "source": [
        "# Creating and Training the Model\n",
        "Here, we are creating a MobileNetV2 model, leveraging transfer learning for better performance. The base layers of the model are frozen to preserve learned features, and new layers are added for the specific task of classifying CIFAR-10 images. This step concludes with training the model on the prepared dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "DoAV4iWZYhhY"
      },
      "outputs": [],
      "source": [
        "def create_and_train_model(train_ds, test_ds):\n",
        "    base_model = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3), include_top=False, weights='imagenet')\n",
        "    base_model.trainable = False\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        base_model,\n",
        "        tf.keras.layers.GlobalAveragePooling2D(),\n",
        "        tf.keras.layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    model.fit(train_ds, epochs=5, validation_data=test_ds)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6cDl-xubkXf"
      },
      "source": [
        "# Converting to TensorFlow Lite with Quantization\n",
        "In this section, we are converting the trained model to TensorFlow Lite format while applying quantization. Quantization reduces the model size and improves performance, making it suitable for deployment on devices with limited resources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8FM2-2FMYlKc"
      },
      "outputs": [],
      "source": [
        "def convert_to_tflite(model):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    return converter.convert()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7lopft6bnre"
      },
      "source": [
        "# Pruning the Model\n",
        "We are now applying pruning to the model. Pruning involves systematically removing weights from the model to reduce its size and complexity. The process uses a pruning schedule to determine which weights to remove and when, balancing model size and performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YSdo13kIYnCg"
      },
      "outputs": [],
      "source": [
        "def apply_pruning_to_model(model, train_ds, test_ds):\n",
        "    pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.0, final_sparsity=0.5, begin_step=0, end_step=1000)\n",
        "    pruned_model = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule=pruning_schedule)\n",
        "\n",
        "    pruned_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    pruned_model.fit(train_ds, epochs=5, validation_data=test_ds, callbacks=[tfmot.sparsity.keras.UpdatePruningStep()])\n",
        "    return pruned_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XML2zvAfbr0U"
      },
      "source": [
        "# Evaluating the TensorFlow Lite Model\n",
        "We are setting up a TensorFlow Lite interpreter and using it to evaluate the quantized model. This involves processing the test dataset and running it through the model to measure its accuracy and performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ex3u-bUdYpjt"
      },
      "outputs": [],
      "source": [
        "def evaluate_tflite_model(interpreter, test_ds):\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    total_seen, total_correct = 0, 0\n",
        "    test_ds = test_ds.unbatch()\n",
        "\n",
        "    for img, label in test_ds:\n",
        "        img = tf.image.resize(img, [input_details[0]['shape'][1], input_details[0]['shape'][2]])\n",
        "        img = tf.expand_dims(img, axis=0)\n",
        "        img = tf.cast(img, tf.float32)  # Corrected line\n",
        "\n",
        "        if img.shape != input_details[0]['shape']:\n",
        "            raise ValueError(f\"Expected input shape {input_details[0]['shape']}, but got {img.shape}\")\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], img)\n",
        "        interpreter.invoke()\n",
        "        output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "        predictions = np.argmax(output_data, axis=1)\n",
        "\n",
        "        total_seen += 1\n",
        "        total_correct += (predictions[0] == label.numpy())\n",
        "\n",
        "    return total_correct / total_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqLkVSIXbum-"
      },
      "source": [
        "# Final Evaluation and Comparison\n",
        "Finally, we are evaluating and comparing the performance of all models - the original, the quantized, and the pruned versions. This comparison is crucial to understand the trade-offs made between model size, speed, and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7okr2sUgYsgP"
      },
      "outputs": [],
      "source": [
        "def load_or_train_model(train_ds, test_ds, model_path):\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"Loading saved model...\")\n",
        "        return tf.keras.models.load_model(model_path)\n",
        "    else:\n",
        "        print(\"Training new model...\")\n",
        "        model = create_and_train_model(train_ds, test_ds)\n",
        "        model.save(model_path)\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myNYyBaHYMia",
        "outputId": "7f4d9341-bfbf-41c8-f885-014f008a30f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading saved model...\n",
            "Loading saved model...\n",
            "157/157 [==============================] - 236s 1s/step - loss: 0.5391 - accuracy: 0.8147\n",
            "157/157 [==============================] - 227s 1s/step - loss: 1.3187 - accuracy: 0.5381\n",
            "Original Model Accuracy: 0.8147000074386597\n",
            "Quantized Model Accuracy: 0.7944\n",
            "Pruned Model Accuracy: 0.538100004196167\n"
          ]
        }
      ],
      "source": [
        "# Specify paths in Google Drive for models\n",
        "model_path = '/content/drive/My Drive/EdgeAI/model.h5'\n",
        "pruned_model_path = '/content/drive/My Drive/EdgeAI/pruned_model.h5'\n",
        "\n",
        "# Main execution flow\n",
        "train_ds, test_ds = load_and_preprocess_data()\n",
        "model = load_or_train_model(train_ds, test_ds, model_path)\n",
        "tflite_model_quant = convert_to_tflite(model)\n",
        "model_for_pruning = load_or_train_model(train_ds, test_ds, pruned_model_path, is_pruned=True)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model_quant)\n",
        "quant_accuracy = evaluate_tflite_model(interpreter, test_ds)\n",
        "\n",
        "original_eval = model.evaluate(test_ds)\n",
        "pruned_eval = model_for_pruning.evaluate(test_ds)\n",
        "\n",
        "print(f\"Original Model Accuracy: {original_eval[1]}\")\n",
        "print(f\"Quantized Model Accuracy: {quant_accuracy}\")\n",
        "print(f\"Pruned Model Accuracy: {pruned_eval[1]}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
